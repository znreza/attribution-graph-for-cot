{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129ef284-5a58-4adb-9056-28feb65ea1b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers torch hf_transfer seaborn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9912c37d-c92e-466c-a26e-52abac701c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Hugging Face cache directory is now set to: /workspace/huggingface_cache\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fdc51560e354669a1c3e3af622c4f40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from huggingface_hub import login\n",
    "\n",
    "import os\n",
    "\n",
    "cache_dir = \"/workspace/huggingface_cache\"\n",
    "os.environ['HF_HOME'] = cache_dir\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "print(f\"✅ Hugging Face cache directory is now set to: {os.environ['HF_HOME']}\")\n",
    "\n",
    "# Add the cloned repository to the Python path\n",
    "sys.path.append('repository/circuit-tracer')\n",
    "sys.path.append('repository/circuit-tracer/demos')\n",
    "\n",
    "# This will prompt you for your token\n",
    "login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "416ea4d0-f964-4796-ab1c-6126b31adc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7c973fe-6cea-4c53-8b90-19ea16aa7c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec53b01cb8914ef889bc080e2ed3e3d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'google/gemma-2-2b'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc110bf-2a90-4f17-9d52-d6ac45854a3e",
   "metadata": {},
   "source": [
    "### Example 1 - Multi-hop Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07168007-920c-4327-9ae5-230f1ad118de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>The capital of state containing Dallas is Austin.\n",
      "\n",
      "The capital of state containing Dallas is Austin.\n",
      "\n",
      "The capital of state containing Dallas is Austin.\n",
      "\n",
      "The capital of state containing Dallas is Austin.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"The capital of state containing Dallas is\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\")#.to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**input_ids, max_new_tokens=32)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb7a2740-f36c-4917-b25d-55e8c34f820c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's think step by step and answer the following question. Question: The capital of the state containing Dallas is Austin. The capital of the state containing Houston is Austin. The capital of the state containing San Antonio is Austin. The capital of the state containing San Diego is Austin. The capital of the state containing San Francisco is Austin. The capital of\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "  \"Let's think step by step and answer the following question. \"\n",
    "  \"Question: The capital of the state containing Dallas is\"\n",
    ")\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"]\n",
    "out = model.generate(input_ids, max_new_tokens=48, do_sample=False, temperature=0.0)\n",
    "print(tokenizer.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "999085ca-9c17-4c7b-8060-20ea9164ac53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the capital of the state containing Dallas? Let me solve this step by step.\n",
      "\n",
      "Step 1:\n",
      "\n",
      "The state containing Dallas is Texas.\n",
      "\n",
      "Step 2:\n",
      "\n",
      "The capital of Texas is Austin.\n",
      "\n",
      "Step 3:\n",
      "\n",
      "The capital of Texas is Austin.\n",
      "\n",
      "Step 4:\n",
      "\n",
      "The capital of Texas is Austin.\n",
      "\n",
      "Step 5:\n",
      "\n",
      "The capital of Texas is Austin.\n",
      "\n",
      "Step 6:\n",
      "\n",
      "The capital of Texas is Austin.\n",
      "\n",
      "Step 7:\n",
      "\n",
      "The capital of Texas is Austin.\n",
      "\n",
      "Step 8:\n",
      "\n",
      "The capital of Texas is Austin.\n",
      "\n",
      "Step 9:\n",
      "\n",
      "The capital of Texas is Austin.\n",
      "\n",
      "Step 10:\n",
      "\n",
      "The\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "  \"What is the capital of the state containing Dallas? Let me solve this step by step.\"\n",
    ")\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"]\n",
    "out = model.generate(input_ids, max_new_tokens=125, do_sample=False, temperature=0.0)\n",
    "print(tokenizer.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83ec4fa-8ab1-4e7e-aebb-b9e668c072d0",
   "metadata": {},
   "source": [
    "### Example 2 - GSM8K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75321a63-b788-4d65-877c-4bfb5488e1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\n",
      "\n",
      "A. $60\n",
      "\n",
      "B. $\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\" #Answer: $10\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\")#.to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**input_ids, max_new_tokens=10)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c1606e1-b9a7-452a-b6ed-46e982f2c181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn? The correct answer is $60.\n",
      "\n",
      "The correct answer is $\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn? The correct answer is\" #Answer: $10\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\")#.to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**input_ids, max_new_tokens=10)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "def964f2-4397-4550-8341-6cd405b71fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\n",
      "\n",
      "A. $60\n",
      "\n",
      "B. $62\n",
      "\n",
      "C. $64\n",
      "\n",
      "D. $66\n",
      "\n",
      "Show more\n",
      "Step 1\n",
      "1 of 2\n",
      "\n",
      "$12\\times 50=600 $\n",
      "\n",
      "The amount of money earned is the product of the number of hours and the hourly rate.\n",
      "\n",
      "Result\n",
      "2 of 2\n",
      "\n",
      "A<eos>\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\" #Answer: $10\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\")#.to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**input_ids, max_new_tokens=125)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b484a96-24f0-4859-a758-ebf2d5228af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>Let's think step by step and answer the following question: Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\n",
      "\n",
      "Step 1\n",
      "1 of 2\n",
      "\n",
      "Let $x$ be the number of hours Weng worked.\n",
      "\n",
      "The amount of money she earned is the product of the number of hours she worked and the hourly rate.\n",
      "\n",
      "$\\begin{align*} \\text{amount of money earned} &= \\text{number of hours worked} \\times \\text{hourly rate} \\\\ &= x \\times \\$12 \\\\ &= \\$12x \\end{align*} $\n",
      "\n",
      "The amount of money she earned is $\\$12x$.\n",
      "\n",
      "Result\n",
      "2 of 2\n",
      "\n",
      "$\\$12x $<eos>\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Let's think step by step and answer the following question: Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\" #Answer: $10\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\")#.to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**input_ids, max_new_tokens=125)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76e68c42-bfa4-4b9e-a3bb-85b766360fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James writes a 3-page letter to 2 different friends twice a week. How many pages does he write a year? The correct answer is 108.\n",
      "\n",
      "The correct answer is 108.\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "  \"James writes a 3-page letter to 2 different friends twice a week. How many pages does he write a year? The correct answer is\" #Answer: 624\n",
    ")\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"]\n",
    "out = model.generate(input_ids, max_new_tokens=15, do_sample=False, temperature=0.0)\n",
    "print(tokenizer.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62095b72-3ee4-4ff8-b778-2f3998dbf0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James writes a 3-page letter to 2 different friends twice a week. How many pages does he write a year? Let me solve this step by step.\n",
      "\n",
      "Step 1: Find the number of weeks in a year.\n",
      "\n",
      "There are 52 weeks in a year.\n",
      "\n",
      "Step 2: Find the number of letters James writes in a year.\n",
      "\n",
      "James writes 2 letters a week.\n",
      "\n",
      "So, he writes 2 x 52 = 104 letters in a year.\n",
      "\n",
      "Step 3: Find the number of pages James writes in a year.\n",
      "\n",
      "James writes 3 pages in a letter.\n",
      "\n",
      "So, he writes 3 x 104 = 312 pages in a year.\n",
      "\n",
      "Therefore, James writes 312 pages in a year.\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "  \"James writes a 3-page letter to 2 different friends twice a week. How many pages does he write a year? Let me solve this step by step.\" #Answer: 624\n",
    ")\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"]\n",
    "out = model.generate(input_ids, max_new_tokens=150, do_sample=False, temperature=0.0)\n",
    "print(tokenizer.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff081cb8-51d0-4f7e-bb5f-31858f53bc5a",
   "metadata": {},
   "source": [
    "#### Gemma IT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d92807d-13fd-4950-9938-680dd0a9a170",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b-it\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"google/gemma-2-2b-it\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098cba7b-c8db-4e99-9145-0e69b63aeff4",
   "metadata": {},
   "source": [
    "### Graph Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "423aba07-af53-4bc8-8fdb-c0725a868772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dde7a8d-0765-4bb6-bb4e-ed731bb8c0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphTokenAnalyzer:\n",
    "    \"\"\"Analyze attribution graphs and map nodes to tokens\"\"\"\n",
    "    \n",
    "    def __init__(self, graph_json: Dict, prompt: str, model_name: str = 'google/gemma-2-2b'):\n",
    "        \"\"\"\n",
    "        Initialize analyzer with graph and prompt\n",
    "        \n",
    "        Args:\n",
    "            graph_json: The graph JSON from circuit-tracer\n",
    "            prompt: The original prompt used to generate the graph\n",
    "            model_name: Model name for tokenizer\n",
    "        \"\"\"\n",
    "        self.graph = graph_json\n",
    "        self.nodes = graph_json.get('nodes', [])\n",
    "        self.links = graph_json.get('links', [])\n",
    "        self.prompt = prompt\n",
    "        \n",
    "        # Load tokenizer to map positions to tokens\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.tokens = self.tokenizer.encode(prompt)\n",
    "        self.token_strings = self.tokenizer.convert_ids_to_tokens(self.tokens)\n",
    "        \n",
    "        # Build lookup dictionaries\n",
    "        self.node_by_id = {node['node_id']: node for node in self.nodes}\n",
    "        self._organize_nodes_by_layer()\n",
    "    \n",
    "    def _organize_nodes_by_layer(self):\n",
    "        \"\"\"Organize nodes by layer for efficient lookup\"\"\"\n",
    "        self.nodes_by_layer = defaultdict(list)\n",
    "        for node in self.nodes:\n",
    "            layer = node.get('layer', '')\n",
    "            if layer != '':\n",
    "                self.nodes_by_layer[layer].append(node)\n",
    "    \n",
    "    def _safe_float(self, value, default=0.0):\n",
    "        \"\"\"Safely convert value to float, handling None\"\"\"\n",
    "        if value is None:\n",
    "            return default\n",
    "        try:\n",
    "            return float(value)\n",
    "        except (ValueError, TypeError):\n",
    "            return default\n",
    "    \n",
    "    def get_token_for_node(self, node: Dict) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Get the token associated with a node\n",
    "        \n",
    "        Args:\n",
    "            node: Node dictionary\n",
    "            \n",
    "        Returns:\n",
    "            Token string if found, None otherwise\n",
    "        \"\"\"\n",
    "        feature_type = node.get('feature_type', '')\n",
    "        ctx_idx = node.get('ctx_idx', -1)\n",
    "        \n",
    "        # Handle None ctx_idx\n",
    "        if ctx_idx is None:\n",
    "            ctx_idx = -1\n",
    "        \n",
    "        # For token/embedding nodes\n",
    "        if 'token' in feature_type.lower() or 'embedding' in feature_type.lower():\n",
    "            if 0 <= ctx_idx < len(self.token_strings):\n",
    "                return self.token_strings[ctx_idx]\n",
    "        \n",
    "        # For logit nodes (output predictions)\n",
    "        if 'logit' in feature_type.lower() or node.get('is_target_logit', False):\n",
    "            # The feature ID might represent the token ID\n",
    "            feature_id = node.get('feature', -1)\n",
    "            if feature_id is not None and feature_id >= 0:\n",
    "                try:\n",
    "                    return self.tokenizer.decode([feature_id])\n",
    "                except:\n",
    "                    return f\"<token_id_{feature_id}>\"\n",
    "        \n",
    "        # For transcoder feature nodes, return position info\n",
    "        if 'transcoder' in feature_type.lower():\n",
    "            if 0 <= ctx_idx < len(self.token_strings):\n",
    "                return f\"at_pos_{ctx_idx}[{self.token_strings[ctx_idx]}]\"\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def get_node_description(self, node: Dict) -> str:\n",
    "        \"\"\"Get a human-readable description of a node\"\"\"\n",
    "        node_id = node.get('node_id', 'unknown')\n",
    "        feature_type = node.get('feature_type', 'unknown')\n",
    "        feature = node.get('feature', '')\n",
    "        layer = node.get('layer', '')\n",
    "        ctx_idx = node.get('ctx_idx', '')\n",
    "        \n",
    "        # Safely get influence and activation\n",
    "        influence = self._safe_float(node.get('influence'), default=0.0)\n",
    "        activation = self._safe_float(node.get('activation'), default=0.0)\n",
    "        \n",
    "        token = self.get_token_for_node(node)\n",
    "        token_str = f\" '{token}'\" if token else \"\"\n",
    "        \n",
    "        return (f\"Node {node_id}: {feature_type} \"\n",
    "                f\"(feature={feature}, layer={layer}, pos={ctx_idx}){token_str} \"\n",
    "                f\"[influence={influence:.4f}, act={activation:.4f}]\")\n",
    "    \n",
    "    def get_top_n_influential_by_layer(\n",
    "        self, \n",
    "        n: int = 10,\n",
    "        layer: Optional[str] = None\n",
    "    ) -> Dict[str, List[Tuple[Dict, float, str]]]:\n",
    "        \"\"\"\n",
    "        Get top N most influential nodes for each layer\n",
    "        \n",
    "        Args:\n",
    "            n: Number of top nodes to return per layer\n",
    "            layer: Specific layer to analyze (None = all layers)\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary mapping layer -> list of (node, influence, token, description) tuples\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        layers_to_analyze = [layer] if layer else sorted(self.nodes_by_layer.keys())\n",
    "        \n",
    "        for layer_id in layers_to_analyze:\n",
    "            nodes = self.nodes_by_layer[layer_id]\n",
    "            \n",
    "            # Filter out nodes with None influence and sort by influence\n",
    "            valid_nodes = [n for n in nodes if n.get('influence') is not None]\n",
    "            sorted_nodes = sorted(\n",
    "                valid_nodes, \n",
    "                key=lambda x: abs(self._safe_float(x.get('influence', 0))), \n",
    "                reverse=True\n",
    "            )\n",
    "            \n",
    "            # Get top N\n",
    "            top_nodes = []\n",
    "            for node in sorted_nodes[:n]:\n",
    "                influence = self._safe_float(node.get('influence', 0))\n",
    "                description = self.get_node_description(node)\n",
    "                token = self.get_token_for_node(node)\n",
    "                top_nodes.append((node, influence, token, description))\n",
    "            \n",
    "            results[layer_id] = top_nodes\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_top_n_activated_by_layer(\n",
    "        self, \n",
    "        n: int = 10,\n",
    "        layer: Optional[str] = None\n",
    "    ) -> Dict[str, List[Tuple[Dict, float, str]]]:\n",
    "        \"\"\"\n",
    "        Get top N most activated nodes for each layer\n",
    "        \n",
    "        Similar to get_top_n_influential_by_layer but sorts by activation\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        layers_to_analyze = [layer] if layer else sorted(self.nodes_by_layer.keys())\n",
    "        \n",
    "        for layer_id in layers_to_analyze:\n",
    "            nodes = self.nodes_by_layer[layer_id]\n",
    "            \n",
    "            # Filter out nodes with None activation and sort\n",
    "            valid_nodes = [n for n in nodes if n.get('activation') is not None]\n",
    "            sorted_nodes = sorted(\n",
    "                valid_nodes, \n",
    "                key=lambda x: abs(self._safe_float(x.get('activation', 0))), \n",
    "                reverse=True\n",
    "            )\n",
    "            \n",
    "            # Get top N\n",
    "            top_nodes = []\n",
    "            for node in sorted_nodes[:n]:\n",
    "                activation = self._safe_float(node.get('activation', 0))\n",
    "                description = self.get_node_description(node)\n",
    "                token = self.get_token_for_node(node)\n",
    "                top_nodes.append((node, activation, token, description))\n",
    "            \n",
    "            results[layer_id] = top_nodes\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def analyze_token_influence_across_layers(self, token_pos: int) -> List[Tuple[str, Dict]]:\n",
    "        \"\"\"\n",
    "        Track how a specific token position influences computation across layers\n",
    "        \n",
    "        Args:\n",
    "            token_pos: Position of token in sequence\n",
    "            \n",
    "        Returns:\n",
    "            List of (layer, node_info) tuples\n",
    "        \"\"\"\n",
    "        token_nodes = []\n",
    "        \n",
    "        for layer_id, nodes in self.nodes_by_layer.items():\n",
    "            for node in nodes:\n",
    "                ctx_idx = node.get('ctx_idx')\n",
    "                if ctx_idx is not None and ctx_idx == token_pos:\n",
    "                    token_nodes.append((layer_id, node))\n",
    "        \n",
    "        # Sort by layer\n",
    "        token_nodes.sort(key=lambda x: int(x[0]) if x[0].isdigit() else 0)\n",
    "        return token_nodes\n",
    "    \n",
    "    def get_output_predictions(self) -> List[Tuple[str, float]]:\n",
    "        \"\"\"\n",
    "        Get predicted output tokens and their probabilities\n",
    "        \n",
    "        Returns:\n",
    "            List of (token, probability) tuples\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        \n",
    "        for node in self.nodes:\n",
    "            if node.get('is_target_logit', False):\n",
    "                token = self.get_token_for_node(node)\n",
    "                prob = self._safe_float(node.get('token_prob', 0))\n",
    "                if token:\n",
    "                    predictions.append((token, prob))\n",
    "        \n",
    "        return sorted(predictions, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    def generate_influence_report(self, top_n: int = 5) -> str:\n",
    "        \"\"\"\n",
    "        Generate a comprehensive report of influential nodes\n",
    "        \n",
    "        Args:\n",
    "            top_n: Number of top nodes to show per layer\n",
    "            \n",
    "        Returns:\n",
    "            Formatted report string\n",
    "        \"\"\"\n",
    "        report = []\n",
    "        report.append(\"=\"*80)\n",
    "        report.append(\"GRAPH INFLUENCE ANALYSIS REPORT\")\n",
    "        report.append(\"=\"*80)\n",
    "        report.append(f\"\\nPrompt: {self.prompt}\")\n",
    "        report.append(f\"Total nodes: {len(self.nodes)}\")\n",
    "        report.append(f\"Total layers analyzed: {len(self.nodes_by_layer)}\")\n",
    "        \n",
    "        # Token information\n",
    "        report.append(f\"\\n--- Input Tokens ---\")\n",
    "        for i, token in enumerate(self.token_strings):\n",
    "            report.append(f\"  Position {i}: '{token}'\")\n",
    "        \n",
    "        # Output predictions\n",
    "        predictions = self.get_output_predictions()\n",
    "        if predictions:\n",
    "            report.append(f\"\\n--- Top Predicted Output Tokens ---\")\n",
    "            for token, prob in predictions[:10]:\n",
    "                report.append(f\"  '{token}': {prob:.4f}\")\n",
    "        \n",
    "        # Top influential nodes by layer\n",
    "        report.append(f\"\\n--- Top {top_n} Most Influential Nodes Per Layer ---\")\n",
    "        influential = self.get_top_n_influential_by_layer(n=top_n)\n",
    "        \n",
    "        for layer_id in sorted(influential.keys(), key=lambda x: int(x) if x.isdigit() else 0):\n",
    "            report.append(f\"\\n>>> Layer {layer_id} <<<\")\n",
    "            for i, (node, influence, token, description) in enumerate(influential[layer_id], 1):\n",
    "                token_info = f\" [Token: {token}]\" if token else \"\"\n",
    "                report.append(f\"  {i}. Influence: {influence:.6f}{token_info}\")\n",
    "                report.append(f\"     Feature: {node.get('feature')}, \"\n",
    "                            f\"Type: {node.get('feature_type', 'N/A')}, \"\n",
    "                            f\"Pos: {node.get('ctx_idx', 'N/A')}\")\n",
    "                activation = self._safe_float(node.get('activation'))\n",
    "                report.append(f\"     Activation: {activation:.4f}\")\n",
    "        \n",
    "        report.append(\"\\n\" + \"=\"*80)\n",
    "        return \"\\n\".join(report)\n",
    "    \n",
    "    def export_influence_matrix(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Export influence values as a matrix [layer x position]\n",
    "        \n",
    "        Returns:\n",
    "            NumPy array with shape (n_layers, n_positions)\n",
    "        \"\"\"\n",
    "        # Get dimensions\n",
    "        numeric_layers = [int(k) for k in self.nodes_by_layer.keys() if k.isdigit()]\n",
    "        if not numeric_layers:\n",
    "            return np.array([])\n",
    "        \n",
    "        max_layer = max(numeric_layers)\n",
    "        max_pos = len(self.token_strings)\n",
    "        \n",
    "        # Initialize matrix\n",
    "        influence_matrix = np.zeros((max_layer + 1, max_pos))\n",
    "        \n",
    "        # Fill matrix\n",
    "        for layer_str, nodes in self.nodes_by_layer.items():\n",
    "            if not layer_str.isdigit():\n",
    "                continue\n",
    "            layer_idx = int(layer_str)\n",
    "            \n",
    "            for node in nodes:\n",
    "                ctx_idx = node.get('ctx_idx')\n",
    "                if ctx_idx is None:\n",
    "                    continue\n",
    "                    \n",
    "                influence = self._safe_float(node.get('influence', 0))\n",
    "                \n",
    "                if 0 <= ctx_idx < max_pos:\n",
    "                    # Aggregate influences at each position\n",
    "                    influence_matrix[layer_idx, ctx_idx] += abs(influence)\n",
    "        \n",
    "        return influence_matrix\n",
    "    \n",
    "    def plot_influence_heatmap(self, save_path: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Plot influence heatmap across layers and token positions\n",
    "        \n",
    "        Args:\n",
    "            save_path: Path to save figure (None = display)\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        \n",
    "        influence_matrix = self.export_influence_matrix()\n",
    "        \n",
    "        if influence_matrix.size == 0:\n",
    "            print(\"No data to plot\")\n",
    "            return\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        \n",
    "        sns.heatmap(\n",
    "            influence_matrix,\n",
    "            cmap='YlOrRd',\n",
    "            xticklabels=self.token_strings,\n",
    "            yticklabels=range(influence_matrix.shape[0]),\n",
    "            cbar_kws={'label': 'Cumulative Influence'},\n",
    "            ax=ax\n",
    "        )\n",
    "        \n",
    "        ax.set_xlabel('Token Position', fontsize=12)\n",
    "        ax.set_ylabel('Layer', fontsize=12)\n",
    "        ax.set_title(f'Influence Heatmap\\nPrompt: {self.prompt[:50]}...', fontsize=14)\n",
    "        \n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            print(f\"✓ Saved heatmap to {save_path}\")\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN USAGE FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_graph_from_file(\n",
    "    json_file: str,\n",
    "    prompt: str,\n",
    "    model_name: str = 'google/gemma-2-2b',\n",
    "    top_n: int = 5,\n",
    "    generate_plot: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Complete analysis of a graph JSON file\n",
    "    \n",
    "    Args:\n",
    "        json_file: Path to the graph JSON file\n",
    "        prompt: The prompt used to generate the graph\n",
    "        model_name: Model name for tokenizer\n",
    "        top_n: Number of top nodes to show per layer\n",
    "        generate_plot: Whether to generate influence heatmap\n",
    "    \"\"\"\n",
    "    # Load graph\n",
    "    print(f\"Loading graph from {json_file}...\")\n",
    "    with open(json_file, 'r') as f:\n",
    "        graph_json = json.load(f)\n",
    "    \n",
    "    # Initialize analyzer\n",
    "    print(\"Initializing analyzer...\")\n",
    "    analyzer = GraphTokenAnalyzer(graph_json, prompt, model_name)\n",
    "    \n",
    "    # Generate report\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    report = analyzer.generate_influence_report(top_n=top_n)\n",
    "    print(report)\n",
    "    \n",
    "    # Get top influential nodes by layer\n",
    "    print(\"\\n--- Extracting Top Influential Nodes by Layer ---\")\n",
    "    influential = analyzer.get_top_n_influential_by_layer(n=top_n)\n",
    "    \n",
    "    # Save to CSV for further analysis\n",
    "    import pandas as pd\n",
    "    \n",
    "    rows = []\n",
    "    for layer, nodes in influential.items():\n",
    "        for rank, (node, influence, token, desc) in enumerate(nodes, 1):\n",
    "            rows.append({\n",
    "                'layer': layer,\n",
    "                'rank': rank,\n",
    "                'node_id': node['node_id'],\n",
    "                'feature': node.get('feature', ''),\n",
    "                'feature_type': node.get('feature_type', ''),\n",
    "                'position': node.get('ctx_idx', ''),\n",
    "                'token': token,\n",
    "                'influence': influence,\n",
    "                'activation': analyzer._safe_float(node.get('activation', 0)),\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    output_csv = json_file.replace('.json', '_top_influential.csv')\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\n✓ Saved top influential nodes to: {output_csv}\")\n",
    "    \n",
    "    # Generate heatmap\n",
    "    if generate_plot:\n",
    "        print(\"\\n--- Generating Influence Heatmap ---\")\n",
    "        output_plot = json_file.replace('.json', '_heatmap.png')\n",
    "        analyzer.plot_influence_heatmap(save_path=output_plot)\n",
    "    \n",
    "    return analyzer, influential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f7e581f-11aa-478b-b881-cd01e3bc9528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph from graphs/dallas-austin.json...\n",
      "Initializing analyzer...\n",
      "\n",
      "================================================================================\n",
      "================================================================================\n",
      "GRAPH INFLUENCE ANALYSIS REPORT\n",
      "================================================================================\n",
      "\n",
      "Prompt: The capital of state containing Dallas is\n",
      "Total nodes: 1503\n",
      "Total layers analyzed: 28\n",
      "\n",
      "--- Input Tokens ---\n",
      "  Position 0: '<bos>'\n",
      "  Position 1: 'The'\n",
      "  Position 2: '▁capital'\n",
      "  Position 3: '▁of'\n",
      "  Position 4: '▁state'\n",
      "  Position 5: '▁containing'\n",
      "  Position 6: '▁Dallas'\n",
      "  Position 7: '▁is'\n",
      "\n",
      "--- Top Predicted Output Tokens ---\n",
      "  ' Austin': 0.3184\n",
      "\n",
      "--- Top 10 Most Influential Nodes Per Layer ---\n",
      "\n",
      ">>> Layer 0 <<<\n",
      "  1. Influence: 0.799523 [Token: at_pos_2[▁capital]]\n",
      "     Feature: 108434900, Type: cross layer transcoder, Pos: 2\n",
      "     Activation: 1.0469\n",
      "  2. Influence: 0.798999 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 46075199, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 1.8203\n",
      "  3. Influence: 0.798158 [Token: at_pos_4[▁state]]\n",
      "     Feature: 23691285, Type: cross layer transcoder, Pos: 4\n",
      "     Activation: 1.1406\n",
      "  4. Influence: 0.798053 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 6615702, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 1.9844\n",
      "  5. Influence: 0.796890 [Token: at_pos_2[▁capital]]\n",
      "     Feature: 33166439, Type: cross layer transcoder, Pos: 2\n",
      "     Activation: 0.9141\n",
      "  6. Influence: 0.796038 [Token: at_pos_4[▁state]]\n",
      "     Feature: 37805859, Type: cross layer transcoder, Pos: 4\n",
      "     Activation: 2.1250\n",
      "  7. Influence: 0.795610 [Token: at_pos_2[▁capital]]\n",
      "     Feature: 32076044, Type: cross layer transcoder, Pos: 2\n",
      "     Activation: 0.8945\n",
      "  8. Influence: 0.793554 [Token: at_pos_2[▁capital]]\n",
      "     Feature: 33656909, Type: cross layer transcoder, Pos: 2\n",
      "     Activation: 0.7617\n",
      "  9. Influence: 0.792680 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 74438300, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 2.1719\n",
      "  10. Influence: 0.792461 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 49496274, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 1.7734\n",
      "\n",
      ">>> Layer E <<<\n",
      "  1. Influence: 0.259992 [Token: ▁of]\n",
      "     Feature: 3, Type: embedding, Pos: 3\n",
      "     Activation: 0.0000\n",
      "  2. Influence: 0.243169 [Token: ▁is]\n",
      "     Feature: 7, Type: embedding, Pos: 7\n",
      "     Activation: 0.0000\n",
      "  3. Influence: 0.221533 [Token: ▁state]\n",
      "     Feature: 4, Type: embedding, Pos: 4\n",
      "     Activation: 0.0000\n",
      "  4. Influence: 0.197605 [Token: ▁containing]\n",
      "     Feature: 5, Type: embedding, Pos: 5\n",
      "     Activation: 0.0000\n",
      "  5. Influence: 0.168449 [Token: ▁Dallas]\n",
      "     Feature: 6, Type: embedding, Pos: 6\n",
      "     Activation: 0.0000\n",
      "  6. Influence: 0.138793 [Token: The]\n",
      "     Feature: 1, Type: embedding, Pos: 1\n",
      "     Activation: 0.0000\n",
      "  7. Influence: 0.100831 [Token: <bos>]\n",
      "     Feature: 0, Type: embedding, Pos: 0\n",
      "     Activation: 0.0000\n",
      "  8. Influence: 0.058525 [Token: ▁capital]\n",
      "     Feature: 2, Type: embedding, Pos: 2\n",
      "     Activation: 0.0000\n",
      "\n",
      ">>> Layer 1 <<<\n",
      "  1. Influence: 0.799941 [Token: at_pos_7[▁is]]\n",
      "     Feature: 11488819, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 1.9453\n",
      "  2. Influence: 0.799836 [Token: at_pos_7[▁is]]\n",
      "     Feature: 18207593, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 2.5312\n",
      "  3. Influence: 0.797737 [Token: at_pos_4[▁state]]\n",
      "     Feature: 94277044, Type: cross layer transcoder, Pos: 4\n",
      "     Activation: 2.2812\n",
      "  4. Influence: 0.797631 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 4884373, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 1.2500\n",
      "  5. Influence: 0.797526 [Token: at_pos_5[▁containing]]\n",
      "     Feature: 64860353, Type: cross layer transcoder, Pos: 5\n",
      "     Activation: 1.9141\n",
      "  6. Influence: 0.796784 [Token: at_pos_5[▁containing]]\n",
      "     Feature: 35275798, Type: cross layer transcoder, Pos: 5\n",
      "     Activation: 3.7656\n",
      "  7. Influence: 0.794964 [Token: at_pos_5[▁containing]]\n",
      "     Feature: 46701278, Type: cross layer transcoder, Pos: 5\n",
      "     Activation: 1.8828\n",
      "  8. Influence: 0.794423 [Token: at_pos_2[▁capital]]\n",
      "     Feature: 21710753, Type: cross layer transcoder, Pos: 2\n",
      "     Activation: 2.0312\n",
      "  9. Influence: 0.794098 [Token: at_pos_3[▁of]]\n",
      "     Feature: 110683, Type: cross layer transcoder, Pos: 3\n",
      "     Activation: 1.4219\n",
      "  10. Influence: 0.793772 [Token: at_pos_3[▁of]]\n",
      "     Feature: 5179369, Type: cross layer transcoder, Pos: 3\n",
      "     Activation: 1.4766\n",
      "\n",
      ">>> Layer 2 <<<\n",
      "  1. Influence: 0.799313 [Token: at_pos_7[▁is]]\n",
      "     Feature: 97017, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 1.9766\n",
      "  2. Influence: 0.798684 [Token: at_pos_2[▁capital]]\n",
      "     Feature: 32332858, Type: cross layer transcoder, Pos: 2\n",
      "     Activation: 1.8516\n",
      "  3. Influence: 0.797948 [Token: at_pos_7[▁is]]\n",
      "     Feature: 9616302, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 2.0938\n",
      "  4. Influence: 0.795287 [Token: at_pos_3[▁of]]\n",
      "     Feature: 17793592, Type: cross layer transcoder, Pos: 3\n",
      "     Activation: 1.9219\n",
      "  5. Influence: 0.794531 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 6449433, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 2.5469\n",
      "  6. Influence: 0.793118 [Token: at_pos_5[▁containing]]\n",
      "     Feature: 12253722, Type: cross layer transcoder, Pos: 5\n",
      "     Activation: 1.5547\n",
      "  7. Influence: 0.791360 [Token: at_pos_3[▁of]]\n",
      "     Feature: 23615625, Type: cross layer transcoder, Pos: 3\n",
      "     Activation: 1.7656\n",
      "  8. Influence: 0.789809 [Token: at_pos_1[The]]\n",
      "     Feature: 48103333, Type: cross layer transcoder, Pos: 1\n",
      "     Activation: 2.7812\n",
      "  9. Influence: 0.788471 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 35460828, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 2.6562\n",
      "  10. Influence: 0.787910 [Token: at_pos_5[▁containing]]\n",
      "     Feature: 8505747, Type: cross layer transcoder, Pos: 5\n",
      "     Activation: 2.5781\n",
      "\n",
      ">>> Layer 3 <<<\n",
      "  1. Influence: 0.799732 [Token: at_pos_5[▁containing]]\n",
      "     Feature: 8086227, Type: cross layer transcoder, Pos: 5\n",
      "     Activation: 2.5625\n",
      "  2. Influence: 0.799209 [Token: at_pos_3[▁of]]\n",
      "     Feature: 61100981, Type: cross layer transcoder, Pos: 3\n",
      "     Activation: 2.2500\n",
      "  3. Influence: 0.795395 [Token: at_pos_3[▁of]]\n",
      "     Feature: 50949461, Type: cross layer transcoder, Pos: 3\n",
      "     Activation: 2.1562\n",
      "  4. Influence: 0.794315 [Token: at_pos_3[▁of]]\n",
      "     Feature: 58530786, Type: cross layer transcoder, Pos: 3\n",
      "     Activation: 2.4844\n",
      "  5. Influence: 0.791470 [Token: at_pos_5[▁containing]]\n",
      "     Feature: 73041737, Type: cross layer transcoder, Pos: 5\n",
      "     Activation: 1.7109\n",
      "  6. Influence: 0.790807 [Token: at_pos_7[▁is]]\n",
      "     Feature: 3873932, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 3.3750\n",
      "  7. Influence: 0.788807 [Token: at_pos_3[▁of]]\n",
      "     Feature: 45931316, Type: cross layer transcoder, Pos: 3\n",
      "     Activation: 2.3594\n",
      "  8. Influence: 0.782886 [Token: at_pos_7[▁is]]\n",
      "     Feature: 99708377, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 2.4844\n",
      "  9. Influence: 0.780192 [Token: at_pos_5[▁containing]]\n",
      "     Feature: 7930149, Type: cross layer transcoder, Pos: 5\n",
      "     Activation: 2.0312\n",
      "  10. Influence: 0.779955 [Token: at_pos_3[▁of]]\n",
      "     Feature: 64616, Type: cross layer transcoder, Pos: 3\n",
      "     Activation: 2.0781\n",
      "\n",
      ">>> Layer 4 <<<\n",
      "  1. Influence: 0.798369 [Token: at_pos_4[▁state]]\n",
      "     Feature: 44467160, Type: cross layer transcoder, Pos: 4\n",
      "     Activation: 3.8281\n",
      "  2. Influence: 0.795503 [Token: at_pos_2[▁capital]]\n",
      "     Feature: 41728675, Type: cross layer transcoder, Pos: 2\n",
      "     Activation: 4.2188\n",
      "  3. Influence: 0.794748 [Token: at_pos_7[▁is]]\n",
      "     Feature: 40756901, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 2.1406\n",
      "  4. Influence: 0.793336 [Token: at_pos_7[▁is]]\n",
      "     Feature: 84441505, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 2.7500\n",
      "  5. Influence: 0.789698 [Token: at_pos_2[▁capital]]\n",
      "     Feature: 92147095, Type: cross layer transcoder, Pos: 2\n",
      "     Activation: 3.2500\n",
      "  6. Influence: 0.784965 [Token: at_pos_7[▁is]]\n",
      "     Feature: 106806415, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 2.7344\n",
      "  7. Influence: 0.784622 [Token: at_pos_7[▁is]]\n",
      "     Feature: 251690, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 2.5781\n",
      "  8. Influence: 0.784392 [Token: at_pos_4[▁state]]\n",
      "     Feature: 35208631, Type: cross layer transcoder, Pos: 4\n",
      "     Activation: 3.1875\n",
      "  9. Influence: 0.783814 [Token: at_pos_7[▁is]]\n",
      "     Feature: 18559273, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 2.1562\n",
      "  10. Influence: 0.782420 [Token: at_pos_3[▁of]]\n",
      "     Feature: 124086376, Type: cross layer transcoder, Pos: 3\n",
      "     Activation: 3.3438\n",
      "\n",
      ">>> Layer 5 <<<\n",
      "  1. Influence: 0.799104 [Token: at_pos_1[The]]\n",
      "     Feature: 86375790, Type: cross layer transcoder, Pos: 1\n",
      "     Activation: 10.1250\n",
      "  2. Influence: 0.798789 [Token: at_pos_7[▁is]]\n",
      "     Feature: 11831674, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 2.4219\n",
      "  3. Influence: 0.798579 [Token: at_pos_4[▁state]]\n",
      "     Feature: 208329, Type: cross layer transcoder, Pos: 4\n",
      "     Activation: 3.2656\n",
      "  4. Influence: 0.798264 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 3971965, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 3.5000\n",
      "  5. Influence: 0.796678 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 4931364, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 3.5625\n",
      "  6. Influence: 0.794856 [Token: at_pos_7[▁is]]\n",
      "     Feature: 4931364, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 3.1875\n",
      "  7. Influence: 0.794640 [Token: at_pos_4[▁state]]\n",
      "     Feature: 55277349, Type: cross layer transcoder, Pos: 4\n",
      "     Activation: 3.0312\n",
      "  8. Influence: 0.793445 [Token: at_pos_7[▁is]]\n",
      "     Feature: 96959769, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 2.9375\n",
      "  9. Influence: 0.793009 [Token: at_pos_5[▁containing]]\n",
      "     Feature: 48280045, Type: cross layer transcoder, Pos: 5\n",
      "     Activation: 3.0312\n",
      "  10. Influence: 0.791801 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 63828045, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 2.5156\n",
      "\n",
      ">>> Layer 6 <<<\n",
      "  1. Influence: 0.798474 [Token: at_pos_3[▁of]]\n",
      "     Feature: 12804323, Type: cross layer transcoder, Pos: 3\n",
      "     Activation: 4.8125\n",
      "  2. Influence: 0.797314 [Token: at_pos_3[▁of]]\n",
      "     Feature: 2224988, Type: cross layer transcoder, Pos: 3\n",
      "     Activation: 4.9688\n",
      "  3. Influence: 0.797208 [Token: at_pos_4[▁state]]\n",
      "     Feature: 48733121, Type: cross layer transcoder, Pos: 4\n",
      "     Activation: 12.1875\n",
      "  4. Influence: 0.796465 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 107817263, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 3.8125\n",
      "  5. Influence: 0.796358 [Token: at_pos_3[▁of]]\n",
      "     Feature: 92840744, Type: cross layer transcoder, Pos: 3\n",
      "     Activation: 4.5312\n",
      "  6. Influence: 0.795931 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 26183459, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 3.1562\n",
      "  7. Influence: 0.795180 [Token: at_pos_3[▁of]]\n",
      "     Feature: 819833, Type: cross layer transcoder, Pos: 3\n",
      "     Activation: 5.9375\n",
      "  8. Influence: 0.792900 [Token: at_pos_5[▁containing]]\n",
      "     Feature: 18883578, Type: cross layer transcoder, Pos: 5\n",
      "     Activation: 3.6406\n",
      "  9. Influence: 0.790918 [Token: at_pos_5[▁containing]]\n",
      "     Feature: 11354988, Type: cross layer transcoder, Pos: 5\n",
      "     Activation: 5.9062\n",
      "  10. Influence: 0.789920 [Token: at_pos_7[▁is]]\n",
      "     Feature: 8721569, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 2.4219\n",
      "\n",
      ">>> Layer 7 <<<\n",
      "  1. Influence: 0.798894 [Token: at_pos_7[▁is]]\n",
      "     Feature: 1271207, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 2.3594\n",
      "  2. Influence: 0.797102 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 47555620, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 4.1250\n",
      "  3. Influence: 0.796571 [Token: at_pos_5[▁containing]]\n",
      "     Feature: 42076543, Type: cross layer transcoder, Pos: 5\n",
      "     Activation: 3.9219\n",
      "  4. Influence: 0.796252 [Token: at_pos_5[▁containing]]\n",
      "     Feature: 39467162, Type: cross layer transcoder, Pos: 5\n",
      "     Activation: 4.7188\n",
      "  5. Influence: 0.790142 [Token: at_pos_7[▁is]]\n",
      "     Feature: 66360952, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 2.0469\n",
      "  6. Influence: 0.788695 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 123080197, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 5.2812\n",
      "  7. Influence: 0.787123 [Token: at_pos_5[▁containing]]\n",
      "     Feature: 130403167, Type: cross layer transcoder, Pos: 5\n",
      "     Activation: 4.6250\n",
      "  8. Influence: 0.785079 [Token: at_pos_7[▁is]]\n",
      "     Feature: 15050833, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 3.1562\n",
      "  9. Influence: 0.781016 [Token: at_pos_5[▁containing]]\n",
      "     Feature: 13305053, Type: cross layer transcoder, Pos: 5\n",
      "     Activation: 4.4062\n",
      "  10. Influence: 0.778287 [Token: at_pos_7[▁is]]\n",
      "     Feature: 42076543, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 3.4688\n",
      "\n",
      ">>> Layer 8 <<<\n",
      "  1. Influence: 0.796996 [Token: at_pos_7[▁is]]\n",
      "     Feature: 25500502, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 2.5469\n",
      "  2. Influence: 0.794206 [Token: at_pos_5[▁containing]]\n",
      "     Feature: 131763252, Type: cross layer transcoder, Pos: 5\n",
      "     Activation: 6.0000\n",
      "  3. Influence: 0.790586 [Token: at_pos_5[▁containing]]\n",
      "     Feature: 107142832, Type: cross layer transcoder, Pos: 5\n",
      "     Activation: 5.0938\n",
      "  4. Influence: 0.789364 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 38786019, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 6.2812\n",
      "  5. Influence: 0.788918 [Token: at_pos_7[▁is]]\n",
      "     Feature: 12642897, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 4.3125\n",
      "  6. Influence: 0.788359 [Token: at_pos_5[▁containing]]\n",
      "     Feature: 60461497, Type: cross layer transcoder, Pos: 5\n",
      "     Activation: 5.2812\n",
      "  7. Influence: 0.787798 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 74462697, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 6.1875\n",
      "  8. Influence: 0.785536 [Token: at_pos_7[▁is]]\n",
      "     Feature: 54262144, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 2.9844\n",
      "  9. Influence: 0.784736 [Token: at_pos_7[▁is]]\n",
      "     Feature: 594586, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 3.7031\n",
      "  10. Influence: 0.775011 [Token: at_pos_2[▁capital]]\n",
      "     Feature: 62512962, Type: cross layer transcoder, Pos: 2\n",
      "     Activation: 7.7812\n",
      "\n",
      ">>> Layer 9 <<<\n",
      "  1. Influence: 0.795717 [Token: at_pos_7[▁is]]\n",
      "     Feature: 19100, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 2.9219\n",
      "  2. Influence: 0.793989 [Token: at_pos_5[▁containing]]\n",
      "     Feature: 53338946, Type: cross layer transcoder, Pos: 5\n",
      "     Activation: 8.6250\n",
      "  3. Influence: 0.792571 [Token: at_pos_5[▁containing]]\n",
      "     Feature: 307710, Type: cross layer transcoder, Pos: 5\n",
      "     Activation: 3.5312\n",
      "  4. Influence: 0.791580 [Token: at_pos_7[▁is]]\n",
      "     Feature: 79512345, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 2.6250\n",
      "  5. Influence: 0.788583 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 61001525, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 6.0625\n",
      "  6. Influence: 0.785422 [Token: at_pos_7[▁is]]\n",
      "     Feature: 95295905, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 2.9531\n",
      "  7. Influence: 0.783930 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 2614031, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 6.0625\n",
      "  8. Influence: 0.781719 [Token: at_pos_4[▁state]]\n",
      "     Feature: 85092525, Type: cross layer transcoder, Pos: 4\n",
      "     Activation: 9.8750\n",
      "  9. Influence: 0.777083 [Token: at_pos_5[▁containing]]\n",
      "     Feature: 10430, Type: cross layer transcoder, Pos: 5\n",
      "     Activation: 5.0625\n",
      "  10. Influence: 0.773899 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 3344981, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 3.3125\n",
      "\n",
      ">>> Layer 10 <<<\n",
      "  1. Influence: 0.799418 [Token: at_pos_7[▁is]]\n",
      "     Feature: 109971854, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 3.6250\n",
      "  2. Influence: 0.796145 [Token: at_pos_5[▁containing]]\n",
      "     Feature: 122109367, Type: cross layer transcoder, Pos: 5\n",
      "     Activation: 3.6875\n",
      "  3. Influence: 0.795072 [Token: at_pos_7[▁is]]\n",
      "     Feature: 22134520, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 4.2812\n",
      "  4. Influence: 0.786331 [Token: at_pos_3[▁of]]\n",
      "     Feature: 110224117, Type: cross layer transcoder, Pos: 3\n",
      "     Activation: 10.3750\n",
      "  5. Influence: 0.782186 [Token: at_pos_7[▁is]]\n",
      "     Feature: 86441515, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 5.7812\n",
      "  6. Influence: 0.781368 [Token: at_pos_7[▁is]]\n",
      "     Feature: 7886395, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 4.7188\n",
      "  7. Influence: 0.780429 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 131909392, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 6.7500\n",
      "  8. Influence: 0.776355 [Token: at_pos_7[▁is]]\n",
      "     Feature: 832684, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 3.0312\n",
      "  9. Influence: 0.769515 [Token: at_pos_7[▁is]]\n",
      "     Feature: 212215, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 2.8438\n",
      "  10. Influence: 0.766954 [Token: at_pos_7[▁is]]\n",
      "     Feature: 97405892, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 3.7500\n",
      "\n",
      ">>> Layer 11 <<<\n",
      "  1. Influence: 0.787010 [Token: at_pos_1[The]]\n",
      "     Feature: 133407933, Type: cross layer transcoder, Pos: 1\n",
      "     Activation: 31.7500\n",
      "  2. Influence: 0.783583 [Token: at_pos_5[▁containing]]\n",
      "     Feature: 5987518, Type: cross layer transcoder, Pos: 5\n",
      "     Activation: 10.3750\n",
      "  3. Influence: 0.781602 [Token: at_pos_7[▁is]]\n",
      "     Feature: 104264008, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 5.5625\n",
      "  4. Influence: 0.774517 [Token: at_pos_1[The]]\n",
      "     Feature: 80589, Type: cross layer transcoder, Pos: 1\n",
      "     Activation: 38.2500\n",
      "  5. Influence: 0.763135 [Token: at_pos_2[▁capital]]\n",
      "     Feature: 114329869, Type: cross layer transcoder, Pos: 2\n",
      "     Activation: 21.8750\n",
      "  6. Influence: 0.739944\n",
      "     Feature: -1, Type: mlp reconstruction error, Pos: 4\n",
      "     Activation: 0.0000\n",
      "  7. Influence: 0.735842 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 832683, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 12.5000\n",
      "  8. Influence: 0.731957 [Token: at_pos_3[▁of]]\n",
      "     Feature: 114329869, Type: cross layer transcoder, Pos: 3\n",
      "     Activation: 22.1250\n",
      "  9. Influence: 0.704525 [Token: at_pos_7[▁is]]\n",
      "     Feature: 55952319, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 6.3750\n",
      "  10. Influence: 0.702374 [Token: at_pos_1[The]]\n",
      "     Feature: 59901973, Type: cross layer transcoder, Pos: 1\n",
      "     Activation: 50.0000\n",
      "\n",
      ">>> Layer 12 <<<\n",
      "  1. Influence: 0.797420 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 59705115, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 8.1250\n",
      "  2. Influence: 0.795824 [Token: at_pos_5[▁containing]]\n",
      "     Feature: 91537202, Type: cross layer transcoder, Pos: 5\n",
      "     Activation: 9.2500\n",
      "  3. Influence: 0.784507 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 35427140, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 6.7500\n",
      "  4. Influence: 0.720094 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 2195547, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 6.3438\n",
      "  5. Influence: 0.688510 [Token: at_pos_1[The]]\n",
      "     Feature: 6835740, Type: cross layer transcoder, Pos: 1\n",
      "     Activation: 41.7500\n",
      "  6. Influence: 0.685103 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 83508413, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 8.9375\n",
      "  7. Influence: 0.678559\n",
      "     Feature: -1, Type: mlp reconstruction error, Pos: 3\n",
      "     Activation: 0.0000\n",
      "  8. Influence: 0.653839\n",
      "     Feature: -1, Type: mlp reconstruction error, Pos: 4\n",
      "     Activation: 0.0000\n",
      "  9. Influence: 0.635147\n",
      "     Feature: -1, Type: mlp reconstruction error, Pos: 5\n",
      "     Activation: 0.0000\n",
      "  10. Influence: 0.633402 [Token: at_pos_1[The]]\n",
      "     Feature: 78206258, Type: cross layer transcoder, Pos: 1\n",
      "     Activation: 57.7500\n",
      "\n",
      ">>> Layer 13 <<<\n",
      "  1. Influence: 0.792351 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 15873781, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 11.0625\n",
      "  2. Influence: 0.779004 [Token: at_pos_7[▁is]]\n",
      "     Feature: 2655346, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 5.8750\n",
      "  3. Influence: 0.754944 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 37380967, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 12.9375\n",
      "  4. Influence: 0.747084\n",
      "     Feature: -1, Type: mlp reconstruction error, Pos: 3\n",
      "     Activation: 0.0000\n",
      "  5. Influence: 0.746040 [Token: at_pos_7[▁is]]\n",
      "     Feature: 42490357, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 5.9062\n",
      "  6. Influence: 0.737432\n",
      "     Feature: -1, Type: mlp reconstruction error, Pos: 4\n",
      "     Activation: 0.0000\n",
      "  7. Influence: 0.725456\n",
      "     Feature: -1, Type: mlp reconstruction error, Pos: 2\n",
      "     Activation: 0.0000\n",
      "  8. Influence: 0.718860 [Token: at_pos_7[▁is]]\n",
      "     Feature: 1131746, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 8.3125\n",
      "  9. Influence: 0.712519 [Token: at_pos_7[▁is]]\n",
      "     Feature: 62412364, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 6.3125\n",
      "  10. Influence: 0.695782 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 6521452, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 21.3750\n",
      "\n",
      ">>> Layer 14 <<<\n",
      "  1. Influence: 0.790364 [Token: at_pos_1[The]]\n",
      "     Feature: 37623460, Type: cross layer transcoder, Pos: 1\n",
      "     Activation: 24.8750\n",
      "  2. Influence: 0.786671 [Token: at_pos_1[The]]\n",
      "     Feature: 3189060, Type: cross layer transcoder, Pos: 1\n",
      "     Activation: 37.0000\n",
      "  3. Influence: 0.774270 [Token: at_pos_3[▁of]]\n",
      "     Feature: 6935935, Type: cross layer transcoder, Pos: 3\n",
      "     Activation: 27.3750\n",
      "  4. Influence: 0.765526 [Token: at_pos_1[The]]\n",
      "     Feature: 24189475, Type: cross layer transcoder, Pos: 1\n",
      "     Activation: 65.5000\n",
      "  5. Influence: 0.750477 [Token: at_pos_1[The]]\n",
      "     Feature: 53483638, Type: cross layer transcoder, Pos: 1\n",
      "     Activation: 50.7500\n",
      "  6. Influence: 0.732448 [Token: at_pos_1[The]]\n",
      "     Feature: 127672195, Type: cross layer transcoder, Pos: 1\n",
      "     Activation: 57.7500\n",
      "  7. Influence: 0.726642\n",
      "     Feature: -1, Type: mlp reconstruction error, Pos: 4\n",
      "     Activation: 0.0000\n",
      "  8. Influence: 0.724603 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 10878765, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 24.8750\n",
      "  9. Influence: 0.713446 [Token: at_pos_7[▁is]]\n",
      "     Feature: 65408188, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 7.5625\n",
      "  10. Influence: 0.708948\n",
      "     Feature: -1, Type: mlp reconstruction error, Pos: 3\n",
      "     Activation: 0.0000\n",
      "\n",
      ">>> Layer 15 <<<\n",
      "  1. Influence: 0.793881 [Token: at_pos_3[▁of]]\n",
      "     Feature: 10172289, Type: cross layer transcoder, Pos: 3\n",
      "     Activation: 31.5000\n",
      "  2. Influence: 0.778526 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 28489910, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 7.9062\n",
      "  3. Influence: 0.775991 [Token: at_pos_4[▁state]]\n",
      "     Feature: 39887, Type: cross layer transcoder, Pos: 4\n",
      "     Activation: 18.1250\n",
      "  4. Influence: 0.775502 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 40468490, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 11.0625\n",
      "  5. Influence: 0.761916 [Token: at_pos_2[▁capital]]\n",
      "     Feature: 337415, Type: cross layer transcoder, Pos: 2\n",
      "     Activation: 18.8750\n",
      "  6. Influence: 0.755656\n",
      "     Feature: -1, Type: mlp reconstruction error, Pos: 2\n",
      "     Activation: 0.0000\n",
      "  7. Influence: 0.724261 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 53898137, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 8.0625\n",
      "  8. Influence: 0.719567 [Token: at_pos_1[The]]\n",
      "     Feature: 294512, Type: cross layer transcoder, Pos: 1\n",
      "     Activation: 105.0000\n",
      "  9. Influence: 0.718150 [Token: at_pos_1[The]]\n",
      "     Feature: 376262, Type: cross layer transcoder, Pos: 1\n",
      "     Activation: 150.0000\n",
      "  10. Influence: 0.696795\n",
      "     Feature: -1, Type: mlp reconstruction error, Pos: 4\n",
      "     Activation: 0.0000\n",
      "\n",
      ">>> Layer 16 <<<\n",
      "  1. Influence: 0.800045 [Token: at_pos_2[▁capital]]\n",
      "     Feature: 25837249, Type: cross layer transcoder, Pos: 2\n",
      "     Activation: 45.0000\n",
      "  2. Influence: 0.785763 [Token: at_pos_2[▁capital]]\n",
      "     Feature: 6046486, Type: cross layer transcoder, Pos: 2\n",
      "     Activation: 37.0000\n",
      "  3. Influence: 0.770652\n",
      "     Feature: -1, Type: mlp reconstruction error, Pos: 2\n",
      "     Activation: 0.0000\n",
      "  4. Influence: 0.738065\n",
      "     Feature: -1, Type: mlp reconstruction error, Pos: 3\n",
      "     Activation: 0.0000\n",
      "  5. Influence: 0.730809 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 28625944, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 10.4375\n",
      "  6. Influence: 0.679223\n",
      "     Feature: -1, Type: mlp reconstruction error, Pos: 5\n",
      "     Activation: 0.0000\n",
      "  7. Influence: 0.669383 [Token: at_pos_7[▁is]]\n",
      "     Feature: 104639794, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 15.6250\n",
      "  8. Influence: 0.660655 [Token: at_pos_7[▁is]]\n",
      "     Feature: 52219073, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 7.4062\n",
      "  9. Influence: 0.588964 [Token: at_pos_7[▁is]]\n",
      "     Feature: 45501013, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 17.8750\n",
      "  10. Influence: 0.585184 [Token: at_pos_7[▁is]]\n",
      "     Feature: 12693224, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 14.6250\n",
      "\n",
      ">>> Layer 17 <<<\n",
      "  1. Influence: 0.781953 [Token: at_pos_1[The]]\n",
      "     Feature: 132608737, Type: cross layer transcoder, Pos: 1\n",
      "     Activation: 49.7500\n",
      "  2. Influence: 0.767598 [Token: at_pos_4[▁state]]\n",
      "     Feature: 88026528, Type: cross layer transcoder, Pos: 4\n",
      "     Activation: 86.0000\n",
      "  3. Influence: 0.764869 [Token: at_pos_1[The]]\n",
      "     Feature: 110197, Type: cross layer transcoder, Pos: 1\n",
      "     Activation: 66.0000\n",
      "  4. Influence: 0.759169 [Token: at_pos_1[The]]\n",
      "     Feature: 77719260, Type: cross layer transcoder, Pos: 1\n",
      "     Activation: 86.0000\n",
      "  5. Influence: 0.752363\n",
      "     Feature: -1, Type: mlp reconstruction error, Pos: 2\n",
      "     Activation: 0.0000\n",
      "  6. Influence: 0.705883 [Token: at_pos_1[The]]\n",
      "     Feature: 38733183, Type: cross layer transcoder, Pos: 1\n",
      "     Activation: 79.0000\n",
      "  7. Influence: 0.654609 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 91483083, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 23.2500\n",
      "  8. Influence: 0.648350 [Token: at_pos_7[▁is]]\n",
      "     Feature: 54397647, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 7.2188\n",
      "  9. Influence: 0.647819 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 30306987, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 50.2500\n",
      "  10. Influence: 0.631050 [Token: at_pos_7[▁is]]\n",
      "     Feature: 30306987, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 14.0625\n",
      "\n",
      ">>> Layer 18 <<<\n",
      "  1. Influence: 0.788023\n",
      "     Feature: -1, Type: mlp reconstruction error, Pos: 5\n",
      "     Activation: 0.0000\n",
      "  2. Influence: 0.781485 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 37762376, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 7.4688\n",
      "  3. Influence: 0.696593 [Token: at_pos_7[▁is]]\n",
      "     Feature: 60747734, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 6.2500\n",
      "  4. Influence: 0.693944 [Token: at_pos_7[▁is]]\n",
      "     Feature: 28716812, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 7.4688\n",
      "  5. Influence: 0.658166 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 14815827, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 24.6250\n",
      "  6. Influence: 0.630459 [Token: at_pos_7[▁is]]\n",
      "     Feature: 546516, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 8.8750\n",
      "  7. Influence: 0.598811 [Token: at_pos_7[▁is]]\n",
      "     Feature: 7494237, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 7.8125\n",
      "  8. Influence: 0.581312\n",
      "     Feature: -1, Type: mlp reconstruction error, Pos: 6\n",
      "     Activation: 0.0000\n",
      "  9. Influence: 0.572510 [Token: at_pos_7[▁is]]\n",
      "     Feature: 44514311, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 7.1250\n",
      "  10. Influence: 0.557305 [Token: at_pos_7[▁is]]\n",
      "     Feature: 128969811, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 10.1250\n",
      "\n",
      ">>> Layer 19 <<<\n",
      "  1. Influence: 0.742565 [Token: at_pos_7[▁is]]\n",
      "     Feature: 96750985, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 7.9688\n",
      "  2. Influence: 0.741801 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 70918075, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 33.0000\n",
      "  3. Influence: 0.674501 [Token: at_pos_7[▁is]]\n",
      "     Feature: 11894983, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 12.5625\n",
      "  4. Influence: 0.606228\n",
      "     Feature: -1, Type: mlp reconstruction error, Pos: 6\n",
      "     Activation: 0.0000\n",
      "  5. Influence: 0.534216 [Token: at_pos_7[▁is]]\n",
      "     Feature: 22858921, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 8.5625\n",
      "  6. Influence: 0.515288 [Token: at_pos_7[▁is]]\n",
      "     Feature: 3024550, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 13.0000\n",
      "  7. Influence: 0.494968 [Token: at_pos_7[▁is]]\n",
      "     Feature: 1633, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 7.7188\n",
      "  8. Influence: 0.444354 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 28106233, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 58.5000\n",
      "  9. Influence: 0.400745 [Token: at_pos_7[▁is]]\n",
      "     Feature: 3686950, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 11.9375\n",
      "  10. Influence: 0.394664 [Token: at_pos_7[▁is]]\n",
      "     Feature: 1073825, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 36.0000\n",
      "\n",
      ">>> Layer 20 <<<\n",
      "  1. Influence: 0.730644 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 29382, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 24.2500\n",
      "  2. Influence: 0.676775 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 67576104, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 18.0000\n",
      "  3. Influence: 0.670558 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 117006732, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 25.7500\n",
      "  4. Influence: 0.608994 [Token: at_pos_7[▁is]]\n",
      "     Feature: 51404709, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 11.4375\n",
      "  5. Influence: 0.590077 [Token: at_pos_7[▁is]]\n",
      "     Feature: 18286107, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 14.4375\n",
      "  6. Influence: 0.563779 [Token: at_pos_7[▁is]]\n",
      "     Feature: 52792929, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 20.2500\n",
      "  7. Influence: 0.562928\n",
      "     Feature: -1, Type: mlp reconstruction error, Pos: 6\n",
      "     Activation: 0.0000\n",
      "  8. Influence: 0.555104 [Token: at_pos_7[▁is]]\n",
      "     Feature: 4853149, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 18.3750\n",
      "  9. Influence: 0.547013 [Token: at_pos_7[▁is]]\n",
      "     Feature: 9159, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 16.7500\n",
      "  10. Influence: 0.450204 [Token: at_pos_7[▁is]]\n",
      "     Feature: 117006732, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 15.7500\n",
      "\n",
      ">>> Layer 21 <<<\n",
      "  1. Influence: 0.764473 [Token: at_pos_7[▁is]]\n",
      "     Feature: 118402944, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 8.8750\n",
      "  2. Influence: 0.759861 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 5060949, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 18.0000\n",
      "  3. Influence: 0.739165 [Token: at_pos_6[▁Dallas]]\n",
      "     Feature: 23239131, Type: cross layer transcoder, Pos: 6\n",
      "     Activation: 11.8125\n",
      "  4. Influence: 0.737115 [Token: at_pos_7[▁is]]\n",
      "     Feature: 5479683, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 6.7500\n",
      "  5. Influence: 0.674041 [Token: at_pos_7[▁is]]\n",
      "     Feature: 14175128, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 16.6250\n",
      "  6. Influence: 0.635723 [Token: at_pos_7[▁is]]\n",
      "     Feature: 71192256, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 14.8750\n",
      "  7. Influence: 0.613352 [Token: at_pos_7[▁is]]\n",
      "     Feature: 90431054, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 9.0625\n",
      "  8. Influence: 0.565050\n",
      "     Feature: -1, Type: mlp reconstruction error, Pos: 6\n",
      "     Activation: 0.0000\n",
      "  9. Influence: 0.560351 [Token: at_pos_7[▁is]]\n",
      "     Feature: 61843859, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 24.7500\n",
      "  10. Influence: 0.559051 [Token: at_pos_7[▁is]]\n",
      "     Feature: 19272714, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 8.9375\n",
      "\n",
      ">>> Layer 22 <<<\n",
      "  1. Influence: 0.713076\n",
      "     Feature: -1, Type: mlp reconstruction error, Pos: 6\n",
      "     Activation: 0.0000\n",
      "  2. Influence: 0.649145 [Token: at_pos_7[▁is]]\n",
      "     Feature: 4534543, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 11.3125\n",
      "  3. Influence: 0.622585 [Token: at_pos_7[▁is]]\n",
      "     Feature: 91469552, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 10.6250\n",
      "  4. Influence: 0.597737 [Token: at_pos_7[▁is]]\n",
      "     Feature: 84688582, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 9.4375\n",
      "  5. Influence: 0.548386 [Token: at_pos_7[▁is]]\n",
      "     Feature: 63208123, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 27.3750\n",
      "  6. Influence: 0.512473 [Token: at_pos_7[▁is]]\n",
      "     Feature: 1462, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 20.7500\n",
      "  7. Influence: 0.407660 [Token: at_pos_7[▁is]]\n",
      "     Feature: 68931388, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 29.8750\n",
      "  8. Influence: 0.401935 [Token: at_pos_7[▁is]]\n",
      "     Feature: 6388502, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 54.0000\n",
      "  9. Influence: 0.367998 [Token: at_pos_7[▁is]]\n",
      "     Feature: 12612730, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 34.5000\n",
      "  10. Influence: 0.357174 [Token: at_pos_7[▁is]]\n",
      "     Feature: 4766305, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 70.5000\n",
      "\n",
      ">>> Layer 23 <<<\n",
      "  1. Influence: 0.799627\n",
      "     Feature: -1, Type: mlp reconstruction error, Pos: 6\n",
      "     Activation: 0.0000\n",
      "  2. Influence: 0.792131 [Token: at_pos_1[The]]\n",
      "     Feature: 3326886, Type: cross layer transcoder, Pos: 1\n",
      "     Activation: 100.5000\n",
      "  3. Influence: 0.767726 [Token: at_pos_7[▁is]]\n",
      "     Feature: 96028987, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 8.8750\n",
      "  4. Influence: 0.767341 [Token: at_pos_7[▁is]]\n",
      "     Feature: 27132637, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 10.1875\n",
      "  5. Influence: 0.748419 [Token: at_pos_7[▁is]]\n",
      "     Feature: 1206657, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 8.0625\n",
      "  6. Influence: 0.690407 [Token: at_pos_7[▁is]]\n",
      "     Feature: 58714842, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 8.7500\n",
      "  7. Influence: 0.682514 [Token: at_pos_7[▁is]]\n",
      "     Feature: 110298354, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 7.1562\n",
      "  8. Influence: 0.623818 [Token: at_pos_7[▁is]]\n",
      "     Feature: 17166846, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 8.5625\n",
      "  9. Influence: 0.620410 [Token: at_pos_7[▁is]]\n",
      "     Feature: 40423512, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 7.6562\n",
      "  10. Influence: 0.602716 [Token: at_pos_7[▁is]]\n",
      "     Feature: 4619256, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 7.6875\n",
      "\n",
      ">>> Layer 24 <<<\n",
      "  1. Influence: 0.787348 [Token: at_pos_7[▁is]]\n",
      "     Feature: 92024936, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 6.0000\n",
      "  2. Influence: 0.763270 [Token: at_pos_7[▁is]]\n",
      "     Feature: 96876215, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 6.3438\n",
      "  3. Influence: 0.763000 [Token: at_pos_7[▁is]]\n",
      "     Feature: 194351, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 5.6562\n",
      "  4. Influence: 0.750038 [Token: at_pos_7[▁is]]\n",
      "     Feature: 10930125, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 9.3125\n",
      "  5. Influence: 0.705689 [Token: at_pos_7[▁is]]\n",
      "     Feature: 38830053, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 8.4375\n",
      "  6. Influence: 0.651252 [Token: at_pos_7[▁is]]\n",
      "     Feature: 16207946, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 22.1250\n",
      "  7. Influence: 0.649410 [Token: at_pos_7[▁is]]\n",
      "     Feature: 48211265, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 16.2500\n",
      "  8. Influence: 0.625349 [Token: at_pos_7[▁is]]\n",
      "     Feature: 49526103, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 8.2500\n",
      "  9. Influence: 0.555545 [Token: at_pos_7[▁is]]\n",
      "     Feature: 122500353, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 31.6250\n",
      "  10. Influence: 0.535687 [Token: at_pos_7[▁is]]\n",
      "     Feature: 22980, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 8.3125\n",
      "\n",
      ">>> Layer 25 <<<\n",
      "  1. Influence: 0.797842 [Token: at_pos_7[▁is]]\n",
      "     Feature: 71251927, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 8.1250\n",
      "  2. Influence: 0.789475 [Token: at_pos_7[▁is]]\n",
      "     Feature: 15116725, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 7.6250\n",
      "  3. Influence: 0.787573 [Token: at_pos_7[▁is]]\n",
      "     Feature: 114723352, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 11.0000\n",
      "  4. Influence: 0.782769 [Token: at_pos_7[▁is]]\n",
      "     Feature: 53835850, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 9.1875\n",
      "  5. Influence: 0.744084 [Token: at_pos_7[▁is]]\n",
      "     Feature: 10100239, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 12.5625\n",
      "  6. Influence: 0.741493 [Token: at_pos_7[▁is]]\n",
      "     Feature: 105509575, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 7.3438\n",
      "  7. Influence: 0.740100 [Token: at_pos_7[▁is]]\n",
      "     Feature: 103140677, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 9.0625\n",
      "  8. Influence: 0.739009 [Token: at_pos_7[▁is]]\n",
      "     Feature: 5413669, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 23.1250\n",
      "  9. Influence: 0.725115 [Token: at_pos_7[▁is]]\n",
      "     Feature: 133702102, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 10.0000\n",
      "  10. Influence: 0.714549 [Token: at_pos_7[▁is]]\n",
      "     Feature: 14501779, Type: cross layer transcoder, Pos: 7\n",
      "     Activation: 8.0625\n",
      "\n",
      ">>> Layer 27 <<<\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Extracting Top Influential Nodes by Layer ---\n",
      "\n",
      "✓ Saved top influential nodes to: graphs/dallas-austin_top_influential.csv\n",
      "\n",
      "--- Generating Influence Heatmap ---\n",
      "✓ Saved heatmap to graphs/dallas-austin_heatmap.png\n",
      "\n",
      "--- Detailed Analysis of Layer 0 ---\n",
      "  Influence: 0.799523\n",
      "  Token: at_pos_2[▁capital]\n",
      "  Type: cross layer transcoder\n",
      "\n",
      "  Influence: 0.798999\n",
      "  Token: at_pos_6[▁Dallas]\n",
      "  Type: cross layer transcoder\n",
      "\n",
      "  Influence: 0.798158\n",
      "  Token: at_pos_4[▁state]\n",
      "  Type: cross layer transcoder\n",
      "\n",
      "  Influence: 0.798053\n",
      "  Token: at_pos_6[▁Dallas]\n",
      "  Type: cross layer transcoder\n",
      "\n",
      "  Influence: 0.796890\n",
      "  Token: at_pos_2[▁capital]\n",
      "  Type: cross layer transcoder\n",
      "\n",
      "  Influence: 0.796038\n",
      "  Token: at_pos_4[▁state]\n",
      "  Type: cross layer transcoder\n",
      "\n",
      "  Influence: 0.795610\n",
      "  Token: at_pos_2[▁capital]\n",
      "  Type: cross layer transcoder\n",
      "\n",
      "  Influence: 0.793554\n",
      "  Token: at_pos_2[▁capital]\n",
      "  Type: cross layer transcoder\n",
      "\n",
      "  Influence: 0.792680\n",
      "  Token: at_pos_6[▁Dallas]\n",
      "  Type: cross layer transcoder\n",
      "\n",
      "  Influence: 0.792461\n",
      "  Token: at_pos_6[▁Dallas]\n",
      "  Type: cross layer transcoder\n",
      "\n",
      "\n",
      "--- Tracking Token at Position 5 Across Layers ---\n",
      "Token: '▁containing'\n",
      "  Layer 0: influence=0.6130, activation=4.7812\n",
      "  Layer 0: influence=0.6929, activation=2.6562\n",
      "  Layer 0: influence=0.6520, activation=3.7188\n",
      "  Layer 0: influence=0.5793, activation=5.8125\n",
      "  Layer 0: influence=0.5322, activation=7.9688\n",
      "\n",
      "--- Model's Top Output Predictions ---\n",
      "  ' Austin': 0.3184\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EXAMPLE USAGE\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    json_file = \"graphs/dallas-austin.json\"  # Path to the JSON file\n",
    "    prompt = \"The capital of state containing Dallas is\"\n",
    "    \n",
    "    # Run analysis\n",
    "    analyzer, influential_nodes = analyze_graph_from_file(\n",
    "        json_file=json_file,\n",
    "        prompt=prompt,\n",
    "        model_name='google/gemma-2-2b',\n",
    "        top_n=10,  # Top 10 per layer\n",
    "        generate_plot=True\n",
    "    )\n",
    "    \n",
    "    # Additional analyses\n",
    "    \n",
    "    # 1. Analyze specific layer\n",
    "    print(\"\\n--- Detailed Analysis of Layer 0 ---\")\n",
    "    layer_0_influential = analyzer.get_top_n_influential_by_layer(n=10, layer=\"0\")\n",
    "    if \"0\" in layer_0_influential:\n",
    "        for node, influence, token, desc in layer_0_influential[\"0\"]:\n",
    "            print(f\"  Influence: {influence:.6f}\")\n",
    "            print(f\"  Token: {token}\")\n",
    "            print(f\"  Type: {node.get('feature_type')}\")\n",
    "            print()\n",
    "    \n",
    "    # 2. Track a specific token across layers\n",
    "    print(\"\\n--- Tracking Token at Position 5 Across Layers ---\")\n",
    "    token_pos = 5\n",
    "    if token_pos < len(analyzer.token_strings):\n",
    "        print(f\"Token: '{analyzer.token_strings[token_pos]}'\")\n",
    "        token_across_layers = analyzer.analyze_token_influence_across_layers(token_pos)\n",
    "        for layer, node in token_across_layers[:5]:  # Show first 5 layers\n",
    "            influence = analyzer._safe_float(node.get('influence', 0))\n",
    "            activation = analyzer._safe_float(node.get('activation', 0))\n",
    "            print(f\"  Layer {layer}: influence={influence:.4f}, activation={activation:.4f}\")\n",
    "    \n",
    "    # 3. Get output predictions\n",
    "    print(\"\\n--- Model's Top Output Predictions ---\")\n",
    "    predictions = analyzer.get_output_predictions()\n",
    "    for token, prob in predictions[:10]:\n",
    "        print(f\"  '{token}': {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1017a03b-3bac-45ef-94c7-8b852edc5f8e",
   "metadata": {},
   "source": [
    "    Early Layers (0-5):\n",
    "    └─> Strong focus on INPUT tokens (\"capital\", \"Dallas\")\n",
    "        └─> Model is ENCODING the question\n",
    "    \n",
    "    Middle Layers (6-20):\n",
    "    └─> Distributed, quiet processing\n",
    "        └─> Model is REASONING about the relationship\n",
    "        └─> \"What state has Dallas?\" → Texas\n",
    "        └─> \"What's Texas's capital?\" → Austin\n",
    "    \n",
    "    Late Layers (21-27):\n",
    "    └─> Some activation near end of sequence\n",
    "        └─> Model is GENERATING the output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec3670c-09a5-4545-9129-b82db38094d9",
   "metadata": {},
   "source": [
    "### Comparison of COT Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06bd8a57-2983-4328-9f21-5190cd339308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from typing import List, Dict, Tuple, Any\n",
    "from transformers import AutoTokenizer\n",
    "from circuit_tracer import attribute, ReplacementModel\n",
    "from circuit_tracer.graph import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bd116a8-e4f0-4284-be69-ccb315bc86fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoTFaithfulnessAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyze whether CoT reasoning text matches internal computational graphs\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model: ReplacementModel, tokenizer: AutoTokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def graph_to_dict(self, graph: Graph) -> Dict:\n",
    "        \"\"\"\n",
    "        Convert Graph object to dictionary using its export method\n",
    "        \n",
    "        Args:\n",
    "            graph: Graph object from circuit-tracer\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary representation with 'nodes' and 'links'\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # The Graph object should have an export or to_dict method\n",
    "            if hasattr(graph, 'export'):\n",
    "                return graph.export()\n",
    "            elif hasattr(graph, 'to_dict'):\n",
    "                return graph.to_dict()\n",
    "            elif hasattr(graph, 'to_json'):\n",
    "                json_str = graph.to_json()\n",
    "                return json.loads(json_str)\n",
    "            else:\n",
    "                # Try to manually extract the data\n",
    "                # The Graph class typically stores data in internal attributes\n",
    "                result = {}\n",
    "                \n",
    "                # Try different ways to access the data\n",
    "                if hasattr(graph, '_data'):\n",
    "                    result = graph._data\n",
    "                elif hasattr(graph, 'data'):\n",
    "                    result = graph.data\n",
    "                elif hasattr(graph, '__dict__'):\n",
    "                    result = graph.__dict__\n",
    "                \n",
    "                # Ensure it has the right structure\n",
    "                if 'nodes' not in result and 'links' not in result:\n",
    "                    # Maybe it's nested\n",
    "                    for key in result.keys():\n",
    "                        if isinstance(result[key], dict) and 'nodes' in result[key]:\n",
    "                            result = result[key]\n",
    "                            break\n",
    "                \n",
    "                return result\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error converting graph: {e}\")\n",
    "            # Return empty structure\n",
    "            return {'nodes': [], 'links': []}\n",
    "    \n",
    "    def save_graph_json(self, graph: Graph, filename: str) -> bool:\n",
    "        \"\"\"\n",
    "        Save graph to JSON file using Graph's built-in method\n",
    "        \n",
    "        Returns:\n",
    "            True if successful, False otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Try the Graph's own save method\n",
    "            if hasattr(graph, 'save'):\n",
    "                graph.save(filename)\n",
    "                print(f\"✓ Saved graph using graph.save() to {filename}\")\n",
    "                return True\n",
    "            elif hasattr(graph, 'to_json'):\n",
    "                with open(filename, 'w') as f:\n",
    "                    f.write(graph.to_json())\n",
    "                print(f\"✓ Saved graph using to_json() to {filename}\")\n",
    "                return True\n",
    "            elif hasattr(graph, 'export'):\n",
    "                with open(filename, 'w') as f:\n",
    "                    json.dump(graph.export(), f, indent=2)\n",
    "                print(f\"✓ Saved graph using export() to {filename}\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"✗ Graph object has no save/export method\")\n",
    "                print(f\"   Available methods: {[m for m in dir(graph) if not m.startswith('_')]}\")\n",
    "                return False\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Could not save graph: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def parse_cot_steps(self, full_text: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"Parse CoT output into reasoning steps\"\"\"\n",
    "        steps = []\n",
    "        lines = full_text.split('\\n')\n",
    "        \n",
    "        current_step = None\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            \n",
    "            if line.startswith('Step '):\n",
    "                if current_step:\n",
    "                    steps.append(current_step)\n",
    "                \n",
    "                try:\n",
    "                    step_num = int(line.split(':')[0].replace('Step', '').strip())\n",
    "                    current_step = {\n",
    "                        'step_number': step_num,\n",
    "                        'step_text': line,\n",
    "                        'claim': ''\n",
    "                    }\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            elif current_step and line:\n",
    "                if current_step['claim']:\n",
    "                    current_step['claim'] += ' ' + line\n",
    "                else:\n",
    "                    current_step['claim'] = line\n",
    "        \n",
    "        if current_step:\n",
    "            steps.append(current_step)\n",
    "        \n",
    "        return steps\n",
    "    \n",
    "    def generate_graphs_for_cot(\n",
    "        self, \n",
    "        prompt: str, \n",
    "        cot_output: str,\n",
    "        save_graphs: bool = True\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"Generate attribution graphs for each point in the CoT sequence\"\"\"\n",
    "        full_text = prompt + cot_output\n",
    "        \n",
    "        # Parse steps\n",
    "        steps = self.parse_cot_steps(cot_output)\n",
    "        \n",
    "        if not steps:\n",
    "            print(\"⚠ No steps found in CoT output\")\n",
    "            return []\n",
    "        \n",
    "        print(f\"Found {len(steps)} steps to analyze\")\n",
    "        \n",
    "        step_graphs = []\n",
    "        \n",
    "        for step in steps:\n",
    "            step_text = step['step_text']\n",
    "            if step['claim']:\n",
    "                step_text += ' ' + step['claim']\n",
    "            \n",
    "            # Find where this step appears\n",
    "            step_start_idx = full_text.find(step['claim']) if step['claim'] else -1\n",
    "            \n",
    "            if step_start_idx == -1:\n",
    "                print(f\"⚠ Could not find step {step['step_number']} in text\")\n",
    "                continue\n",
    "            \n",
    "            # Get text up to END of this step\n",
    "            text_up_to_step = full_text[:step_start_idx + len(step['claim'])]\n",
    "            \n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Step {step['step_number']}: {step['step_text']}\")\n",
    "            print(f\"Claim: {step['claim']}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            try:\n",
    "                # Generate attribution graph\n",
    "                graph_obj = attribute(\n",
    "                    prompt=text_up_to_step,\n",
    "                    model=self.model,\n",
    "                    max_n_logits=10,\n",
    "                    desired_logit_prob=0.95,\n",
    "                    verbose=False\n",
    "                )\n",
    "                \n",
    "                print(f\"✓ Graph generated\")\n",
    "                print(f\"  Type: {type(graph_obj)}\")\n",
    "                print(f\"  Methods: {[m for m in dir(graph_obj) if not m.startswith('_') and callable(getattr(graph_obj, m))][:10]}\")\n",
    "                \n",
    "                step_info = {\n",
    "                    'step_number': step['step_number'],\n",
    "                    'step_text': step['step_text'],\n",
    "                    'claim': step['claim'],\n",
    "                    'text_up_to_step': text_up_to_step,\n",
    "                    'graph_object': graph_obj,  # Store the object\n",
    "                    'tokens': self.tokenizer.encode(text_up_to_step)\n",
    "                }\n",
    "                \n",
    "                # Try to save using Graph's own method\n",
    "                if save_graphs:\n",
    "                    filename = f\"step_{step['step_number']}_graph.json\"\n",
    "                    success = self.save_graph_json(graph_obj, filename)\n",
    "                    \n",
    "                    if success:\n",
    "                        # Load it back to get the dict format\n",
    "                        try:\n",
    "                            with open(filename, 'r') as f:\n",
    "                                graph_dict = json.load(f)\n",
    "                                step_info['graph'] = graph_dict\n",
    "                                print(f\"✓ Loaded back: {len(graph_dict.get('nodes', []))} nodes\")\n",
    "                        except:\n",
    "                            print(f\"⚠ Could not load back the saved graph\")\n",
    "                            step_info['graph'] = {'nodes': [], 'links': []}\n",
    "                    else:\n",
    "                        step_info['graph'] = {'nodes': [], 'links': []}\n",
    "                else:\n",
    "                    # Try to convert\n",
    "                    step_info['graph'] = self.graph_to_dict(graph_obj)\n",
    "                \n",
    "                step_graphs.append(step_info)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error for step {step['step_number']}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "        \n",
    "        return step_graphs\n",
    "    \n",
    "    def compare_cot_vs_direct(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        direct_answer: str,\n",
    "        cot_answer: str\n",
    "    ) -> Dict:\n",
    "        \"\"\"Compare computational graphs for direct vs CoT responses\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"GENERATING DIRECT ANSWER GRAPH\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Generate graph for direct answer\n",
    "        direct_graph_obj = attribute(\n",
    "            prompt=prompt + direct_answer,\n",
    "            model=self.model,\n",
    "            max_n_logits=10,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        print(f\"✓ Direct graph generated\")\n",
    "        \n",
    "        # Save and load back\n",
    "        direct_filename = \"direct_graph.json\"\n",
    "        success = self.save_graph_json(direct_graph_obj, direct_filename)\n",
    "        \n",
    "        if success:\n",
    "            with open(direct_filename, 'r') as f:\n",
    "                direct_graph = json.load(f)\n",
    "        else:\n",
    "            direct_graph = self.graph_to_dict(direct_graph_obj)\n",
    "        \n",
    "        direct_nodes = len(direct_graph.get('nodes', []))\n",
    "        direct_edges = len(direct_graph.get('links', []))\n",
    "        \n",
    "        print(f\"  Nodes: {direct_nodes}, Edges: {direct_edges}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"GENERATING COT GRAPHS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Generate graphs for CoT\n",
    "        cot_graphs = self.generate_graphs_for_cot(prompt, cot_answer)\n",
    "        \n",
    "        # Compare\n",
    "        if len(cot_graphs) > 0:\n",
    "            cot_nodes_list = [len(g['graph'].get('nodes', [])) for g in cot_graphs]\n",
    "            cot_edges_list = [len(g['graph'].get('links', [])) for g in cot_graphs]\n",
    "            \n",
    "            cot_nodes_avg = sum(cot_nodes_list) / len(cot_nodes_list) if cot_nodes_list else 0\n",
    "            cot_edges_avg = sum(cot_edges_list) / len(cot_edges_list) if cot_edges_list else 0\n",
    "            \n",
    "            print(f\"\\n✓ Generated {len(cot_graphs)} CoT step graphs\")\n",
    "            for i, (nodes, edges) in enumerate(zip(cot_nodes_list, cot_edges_list), 1):\n",
    "                print(f\"  Step {i}: {nodes} nodes, {edges} edges\")\n",
    "        else:\n",
    "            cot_nodes_avg = 0\n",
    "            cot_edges_avg = 0\n",
    "            print(\"\\n⚠ No CoT graphs generated\")\n",
    "        \n",
    "        comparison = {\n",
    "            'direct': {\n",
    "                'num_nodes': direct_nodes,\n",
    "                'num_edges': direct_edges,\n",
    "                'graph': direct_graph\n",
    "            },\n",
    "            'cot': {\n",
    "                'num_steps': len(cot_graphs),\n",
    "                'avg_nodes_per_step': cot_nodes_avg,\n",
    "                'avg_edges_per_step': cot_edges_avg,\n",
    "                'step_graphs': cot_graphs\n",
    "            },\n",
    "            'metrics': {\n",
    "                'nodes_ratio': cot_nodes_avg / direct_nodes if direct_nodes > 0 else 0,\n",
    "                'edges_ratio': cot_edges_avg / direct_edges if direct_edges > 0 else 0\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return comparison\n",
    "\n",
    "\n",
    "class CoTGraphComparator:\n",
    "    \"\"\"Compare multiple CoT graphs to find patterns\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.step_graphs = []\n",
    "    \n",
    "    def add_step_graph(self, step_info: Dict):\n",
    "        \"\"\"Add a CoT step's graph\"\"\"\n",
    "        self.step_graphs.append(step_info)\n",
    "    \n",
    "    def find_key_entities_in_steps(self) -> Dict[str, List[int]]:\n",
    "        \"\"\"\n",
    "        Find which steps mention key entities (e.g., \"Texas\", \"Austin\")\n",
    "        \n",
    "        Returns:\n",
    "            Dict mapping entity -> list of step numbers where it appears\n",
    "        \"\"\"\n",
    "        entity_appearances = {\n",
    "            'Texas': [],\n",
    "            'Dallas': [],\n",
    "            'Austin': [],\n",
    "            'capital': [],\n",
    "            'state': []\n",
    "        }\n",
    "        \n",
    "        for step_info in self.step_graphs:\n",
    "            step_num = step_info['step_number']\n",
    "            claim = step_info['claim'].lower()\n",
    "            \n",
    "            for entity in entity_appearances.keys():\n",
    "                if entity.lower() in claim:\n",
    "                    entity_appearances[entity].append(step_num)\n",
    "        \n",
    "        return entity_appearances\n",
    "    \n",
    "    def track_entity_influence_across_steps(\n",
    "        self,\n",
    "        entity: str,\n",
    "        tokenizer: AutoTokenizer\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Track how a specific entity's influence changes across CoT steps\n",
    "        \n",
    "        Args:\n",
    "            entity: Entity name (e.g., \"Texas\")\n",
    "            \n",
    "        Returns:\n",
    "            List of influence metrics per step\n",
    "        \"\"\"\n",
    "        entity_token_ids = tokenizer.encode(entity, add_special_tokens=False)\n",
    "        \n",
    "        influence_trajectory = []\n",
    "        \n",
    "        for step_info in self.step_graphs:\n",
    "            graph = step_info['graph']\n",
    "            nodes = graph.get('nodes', [])\n",
    "            \n",
    "            # Find nodes related to this entity\n",
    "            entity_influence = 0\n",
    "            entity_nodes = 0\n",
    "            \n",
    "            for node in nodes:\n",
    "                # Check if this node relates to the entity\n",
    "                influence = node.get('influence', 0)\n",
    "                if influence and influence > 0:\n",
    "                    entity_influence += abs(influence)\n",
    "                    entity_nodes += 1\n",
    "            \n",
    "            influence_trajectory.append({\n",
    "                'step_number': step_info['step_number'],\n",
    "                'claim': step_info['claim'],\n",
    "                'entity_total_influence': entity_influence,\n",
    "                'entity_node_count': entity_nodes\n",
    "            })\n",
    "        \n",
    "        return influence_trajectory\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN ANALYSIS FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_cot_faithfulness(\n",
    "    model: ReplacementModel,\n",
    "    tokenizer: AutoTokenizer,\n",
    "    prompt: str,\n",
    "    generate_response: bool = True\n",
    "):\n",
    "    \"\"\"Complete CoT faithfulness analysis\"\"\"\n",
    "    \n",
    "    analyzer = CoTFaithfulnessAnalyzer(model, tokenizer)\n",
    "    \n",
    "    # Use your example output\n",
    "    cot_output = \"\"\"\n",
    "Step 1:\n",
    "\n",
    "The state containing Dallas is Texas.\n",
    "\n",
    "Step 2:\n",
    "\n",
    "The capital of Texas is Austin.\n",
    "\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COT OUTPUT:\")\n",
    "    print(\"=\"*80)\n",
    "    print(cot_output)\n",
    "    \n",
    "    # Compare with direct answer\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPARING COT VS DIRECT ANSWER\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    direct_answer = \" Austin\"\n",
    "    comparison = analyzer.compare_cot_vs_direct(\n",
    "        prompt=\"What is the capital of the state containing Dallas?\",\n",
    "        direct_answer=direct_answer,\n",
    "        cot_answer=cot_output\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"COMPARISON RESULTS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"\\nDirect answer:\")\n",
    "    print(f\"  Nodes: {comparison['direct']['num_nodes']}\")\n",
    "    print(f\"  Edges: {comparison['direct']['num_edges']}\")\n",
    "    \n",
    "    print(f\"\\nCoT (average per step):\")\n",
    "    print(f\"  Steps: {comparison['cot']['num_steps']}\")\n",
    "    print(f\"  Avg nodes: {comparison['cot']['avg_nodes_per_step']:.1f}\")\n",
    "    print(f\"  Avg edges: {comparison['cot']['avg_edges_per_step']:.1f}\")\n",
    "    \n",
    "    if comparison['metrics']['nodes_ratio'] > 0:\n",
    "        print(f\"\\nRatios:\")\n",
    "        print(f\"  Node ratio (CoT/Direct): {comparison['metrics']['nodes_ratio']:.2f}\")\n",
    "        print(f\"  Edge ratio (CoT/Direct): {comparison['metrics']['edges_ratio']:.2f}\")\n",
    "    \n",
    "    return comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b005b9d-d345-4fef-9ba8-f4627ac70196",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24f910076e54940b0e71a42c473aa9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model google/gemma-2-2b into HookedTransformer\n",
      "\n",
      "================================================================================\n",
      "COT OUTPUT:\n",
      "================================================================================\n",
      "\n",
      "Step 1:\n",
      "\n",
      "The state containing Dallas is Texas.\n",
      "\n",
      "Step 2:\n",
      "\n",
      "The capital of Texas is Austin.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "COMPARING COT VS DIRECT ANSWER\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "GENERATING DIRECT ANSWER GRAPH\n",
      "================================================================================\n",
      "✓ Direct graph generated\n",
      "✗ Graph object has no save/export method\n",
      "   Available methods: ['activation_values', 'active_features', 'adjacency_matrix', 'cfg', 'from_pt', 'input_string', 'input_tokens', 'logit_probabilities', 'logit_tokens', 'n_pos', 'scan', 'selected_features', 'to', 'to_pt']\n",
      "  Nodes: 0, Edges: 0\n",
      "\n",
      "================================================================================\n",
      "GENERATING COT GRAPHS\n",
      "================================================================================\n",
      "Found 2 steps to analyze\n",
      "\n",
      "============================================================\n",
      "Step 1: Step 1:\n",
      "Claim: The state containing Dallas is Texas.\n",
      "============================================================\n",
      "✓ Graph generated\n",
      "  Type: <class 'circuit_tracer.graph.Graph'>\n",
      "  Methods: ['from_pt', 'to', 'to_pt']\n",
      "✗ Graph object has no save/export method\n",
      "   Available methods: ['activation_values', 'active_features', 'adjacency_matrix', 'cfg', 'from_pt', 'input_string', 'input_tokens', 'logit_probabilities', 'logit_tokens', 'n_pos', 'scan', 'selected_features', 'to', 'to_pt']\n",
      "\n",
      "============================================================\n",
      "Step 2: Step 2:\n",
      "Claim: The capital of Texas is Austin.\n",
      "============================================================\n",
      "✓ Graph generated\n",
      "  Type: <class 'circuit_tracer.graph.Graph'>\n",
      "  Methods: ['from_pt', 'to', 'to_pt']\n",
      "✗ Graph object has no save/export method\n",
      "   Available methods: ['activation_values', 'active_features', 'adjacency_matrix', 'cfg', 'from_pt', 'input_string', 'input_tokens', 'logit_probabilities', 'logit_tokens', 'n_pos', 'scan', 'selected_features', 'to', 'to_pt']\n",
      "\n",
      "✓ Generated 2 CoT step graphs\n",
      "  Step 1: 0 nodes, 0 edges\n",
      "  Step 2: 0 nodes, 0 edges\n",
      "\n",
      "================================================================================\n",
      "COMPARISON RESULTS\n",
      "================================================================================\n",
      "\n",
      "Direct answer:\n",
      "  Nodes: 0\n",
      "  Edges: 0\n",
      "\n",
      "CoT (average per step):\n",
      "  Steps: 2\n",
      "  Avg nodes: 0.0\n",
      "  Avg edges: 0.0\n",
      "\n",
      "✓ Analysis complete!\n",
      "Generated graphs saved as step_N_graph.json\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# RUN THE ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load model\n",
    "    model_name = 'google/gemma-2-2b'\n",
    "    transcoder_name = \"gemma\"\n",
    "    \n",
    "    model = ReplacementModel.from_pretrained(\n",
    "        model_name, \n",
    "        transcoder_name, \n",
    "        dtype=torch.bfloat16\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # Run analysis\n",
    "    prompt = \"What is the capital of the state containing Dallas? Let me solve this step by step.\"\n",
    "    \n",
    "    results = analyze_cot_faithfulness(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        prompt=prompt,\n",
    "        generate_response=False  # Use your example output\n",
    "    )\n",
    "    \n",
    "    # Save results\n",
    "    print(\"\\n✓ Analysis complete!\")\n",
    "    print(\"Generated graphs saved as step_N_graph.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1e4b58-7ba7-4267-a11b-7b84e78cdb99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35821f25-b270-4ede-8f1f-e9ba85467ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
